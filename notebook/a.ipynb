{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "sys.path.append('/app/src')\n",
    "\n",
    "\n",
    "# これをしないと，sagemathが勝手にintやfloatをinteger型やRealNuber型に変換してしまうしてしまう\n",
    "preparser(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader.data import _load_data, SimpleDataCollator\n",
    "from dataset.tokernizer import set_tokenizer, set_vocab, set_vocab_ver2\n",
    "from torch.utils.data import DataLoader\n",
    "from loader.model import load_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'C1 E3 E0 + C1 E2 E0 + C6 E1 E2 + C6 E0 E2 + C1 E0 E1 [SEP] C1 E4 E0 + C2 E3 E0 + C6 E2 E2 + C1 E2 E0 + C5 E1 E2 + C1 E1 E1 + C1 E1 E0 + C6 E0 E2 + C1 E0 E1 + C1 E0 E0', 'target': 'C1 E1 E0 + C1 E0 E0 [SEP] C1 E0 E1', 'input_mask': None, 'target_mask': None}\n",
      "{'input': 'C1 E3 E0 + C1 E2 E0 + C6 E1 E2 + C6 E0 E2 + C1 E0 E1 [SEP] C1 E4 E0 + C2 E3 E0 + C6 E2 E2 + C1 E2 E0 + C5 E1 E2 + C1 E1 E1 + C1 E1 E0 + C6 E0 E2 + C1 E0 E1 + C1 E0 E0', 'target': 'C1 E1 E0 + C1 E0 E0 [SEP] C1 E0 E1', 'input_mask': None, 'target_mask': None}\n"
     ]
    }
   ],
   "source": [
    "num_variables = 2\n",
    "field = 'GF7'\n",
    "max_coefficient = 200\n",
    "max_degree=20\n",
    "continous_ids = [2]\n",
    "\n",
    "params = {'encoding_method': 'standard',\n",
    "          'd_model': 512,\n",
    "          'nhead': 8,\n",
    "          'num_encoder_layers': 6,\n",
    "          'num_decoder_layers': 6,\n",
    "          'dim_feedforward': 2048,\n",
    "          'dropout': 0.1,\n",
    "          'max_sequence_length': 10000,\n",
    "          'positional_encoding': 'embedding',\n",
    "          'regression_weight': 1.0,}\n",
    "\n",
    "import argparse\n",
    "\n",
    "params = argparse.Namespace(**params)\n",
    "\n",
    "\n",
    "trainset = _load_data('./data/shape/shape_n=2_field=GF7/data_GF7_n=2.train.lex.infix')\n",
    "testset = _load_data('./data/shape/shape_n=2_field=GF7/data_GF7_n=2.test.lex.infix')\n",
    "\n",
    "print(trainset[0])\n",
    "print(testset[0])\n",
    "\n",
    "vocab = set_vocab(num_variables, \n",
    "                  field=field, \n",
    "                  max_coeff=max_coefficient, \n",
    "                  max_degree=max_degree, \n",
    "                  continuous_coefficient=False, \n",
    "                continuous_exponent=False)\n",
    "\n",
    "tokenizer = set_tokenizer(vocab)\n",
    "\n",
    "dc = SimpleDataCollator(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input torch.Size([16, 276])\n",
      "decoder_input torch.Size([16, 32])\n",
      "encoder_padding_mask torch.Size([16, 276])\n",
      "decoder_padding_mask torch.Size([16, 32])\n",
      "labels torch.Size([16, 32])\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(trainset, collate_fn=dc, batch_size=16, shuffle=True)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder_input', 'decoder_input', 'encoder_padding_mask', 'decoder_padding_mask', 'labels'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 12, 11, 32,  5, 11, 13, 40,  9, 12, 13, 32,  4, 12, 12, 32,  8, 11,\n",
       "        15, 32,  6, 11, 14, 32,  9, 11, 13, 32,  4, 11, 12, 38, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "        36, 36, 36, 36, 36, 36])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['encoder_input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 12, 11, 32,  5, 11, 13, 40,  4, 11, 14, 32,  9, 11, 13, 32,  4, 11,\n",
       "         12, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  4, 11, 14, 40,  4, 11, 16, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  6, 11, 12, 40,  4, 11, 14, 32,  9, 11, 13, 32,  4, 11,\n",
       "         12, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  8, 11, 12, 40,  4, 11, 13, 32,  5, 11, 12, 32,  6, 11,\n",
       "         11, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  5, 11, 13, 32,  9, 11, 11, 40,  4, 11, 14, 38, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 14, 32,  7, 11, 13, 32,  9, 11,\n",
       "         11, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  6, 11, 12, 32,  9, 11, 11, 40,  4, 11, 15, 32,  6, 11,\n",
       "         11, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 15, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  5, 11, 14, 32,  7, 11, 13, 32,  8, 11, 11, 40,  4, 11,\n",
       "         16, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  9, 11, 15, 32,  7, 11, 11, 40,  4, 11, 16, 32,  4, 11,\n",
       "         14, 32,  8, 11, 13, 32,  9, 11, 12, 32,  7, 11, 11, 38],\n",
       "        [ 4, 12, 11, 32,  9, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  4, 11, 12, 32,  9, 11, 11, 40,  4, 11, 16, 32,  5, 11,\n",
       "         13, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  8, 11, 11, 40,  4, 11, 12, 32,  4, 11, 11, 38, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  7, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  6, 11, 11, 40,  4, 11, 13, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  4, 11, 12, 40,  4, 11, 13, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# パディングトークンは意味を持たないので，このトークンに注意を向けないように教えてあげる\n",
    "batch['encoder_padding_mask'] # ['PAD']のところがTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 12, 11,  ..., 36, 36, 36],\n",
       "        [ 4, 12, 11,  ..., 36, 36, 36],\n",
       "        [ 4, 13, 11,  ..., 36, 36, 36],\n",
       "        ...,\n",
       "        [ 5, 15, 11,  ..., 36, 36, 36],\n",
       "        [ 4, 12, 11,  ..., 36, 36, 36],\n",
       "        [ 5, 15, 11,  ..., 36, 36, 36]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.vocab['[PAD]'])\n",
    "batch['encoder_input'] # 36が　['PAD']のトークンID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.3",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
