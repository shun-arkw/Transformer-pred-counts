{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd '/app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "sys.path.append('/app/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from loader.data import _load_data, SimpleDataCollator, HybridDataCollator\n",
    "from loader.model import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from dataset.tokernizer import set_tokenizer, set_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "num_variables = 2\n",
    "field = 'QQ'\n",
    "max_coefficient = 100\n",
    "max_degree=20\n",
    "continous_ids = [2]\n",
    "\n",
    "params = {'encoding_method': 'hybrid',\n",
    "          'd_model': 256,\n",
    "          'nhead': 4,\n",
    "          'num_encoder_layers': 2,\n",
    "          'num_decoder_layers': 2,\n",
    "          'dim_feedforward': 1024,\n",
    "          'dropout': 0.1,\n",
    "          'max_sequence_length': 512,\n",
    "          'positional_encoding': 'embedding',\n",
    "          'regression_weight': 1.0,}\n",
    "\n",
    "import argparse\n",
    "\n",
    "params = argparse.Namespace(**params)\n",
    "\n",
    "vocab = set_vocab(num_variables, \n",
    "                  field=field, \n",
    "                  max_coeff=max_coefficient, \n",
    "                  max_degree=max_degree, \n",
    "                  continuous_coefficient=False, \n",
    "                continuous_exponent=False)\n",
    "tokenizer = set_tokenizer(vocab)\n",
    "model = load_model(params, vocab=vocab, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "task = 'shape'\n",
    "encoding = 'hybrid'\n",
    "n, field = 2, 'GF7'\n",
    "data_name = f'{task}_n={n}_field={field}'\n",
    "data_path = f'data/{task}/{data_name}/data_{field}_n={n}.test.lex.infix'\n",
    "\n",
    "testset     = _load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dc = HybridDataCollator(tokenizer)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, collate_fn=dc, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# task = 'shape'\n",
    "# encoding = 'standard'\n",
    "\n",
    "# n, field = 2, 'GF7'\n",
    "# data_name = f'{task}_n={n}_field={field}'\n",
    "# data_path = f'data/{task}/{data_name}/data_{field}_n={n}.test.lex.infix'\n",
    "\n",
    "# data_config_path = f'config/{data_name}.yaml'\n",
    "# _save_path = f'{field}_n={n}_ep=8_bs=16'\n",
    "# save_path = f'results/{task}/{encoding}_embedding/{_save_path}'\n",
    "# # save_path = f'results/{task}/{encoding}/dryrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for key in batch:\n",
    "    batch[key] = batch[key].to(model.device) if isinstance(batch[key], torch.Tensor) else batch[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(19.9327, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'loss_clf': tensor(5.6199, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       " 'loss_rg': tensor(14.3128, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " 'logits': tensor([[[-0.7997,  0.1777, -0.4062,  ...,  0.0946, -0.1072, -0.6497],\n",
       "          [ 0.1215,  0.7225, -0.7747,  ...,  1.2960, -0.0859, -0.2309],\n",
       "          [-0.5851, -0.0074, -0.6108,  ..., -0.1392,  0.0496, -1.0368],\n",
       "          ...,\n",
       "          [-0.2318,  0.3845, -1.1978,  ...,  0.1619, -0.4243,  1.0051],\n",
       "          [-0.5707,  0.4581, -0.5036,  ...,  0.0650, -0.1025,  0.2354],\n",
       "          [-0.5423, -0.5598, -0.8385,  ...,  0.3655,  1.3766, -0.0080]],\n",
       " \n",
       "         [[-0.8181, -0.0689, -0.1057,  ..., -0.0082, -0.4242, -0.6536],\n",
       "          [ 0.0495,  0.5423, -0.7644,  ...,  1.3736, -0.0865, -0.0540],\n",
       "          [-0.6605,  0.0864, -0.4809,  ..., -0.0854,  0.1100, -1.1429],\n",
       "          ...,\n",
       "          [-0.3453,  0.0089, -1.0978,  ...,  0.1233, -0.3788,  0.5984],\n",
       "          [-0.4874,  0.4503, -0.5650,  ...,  0.1287, -0.1283, -0.0689],\n",
       "          [-0.5728, -1.0142, -0.5861,  ...,  0.5620,  1.4657, -0.1066]],\n",
       " \n",
       "         [[-0.8225, -0.0807, -0.1729,  ...,  0.1287, -0.2278, -0.7739],\n",
       "          [ 0.0758,  0.7071, -0.8730,  ...,  1.4156, -0.2210, -0.3481],\n",
       "          [-0.8861, -0.0824, -0.7213,  ..., -0.0173, -0.0724, -0.8789],\n",
       "          ...,\n",
       "          [-0.0940,  0.2687, -0.9500,  ...,  0.0359, -0.1886,  0.8044],\n",
       "          [-0.8698,  0.4918, -0.4392,  ..., -0.0153, -0.3165,  0.0926],\n",
       "          [-0.3844, -0.7870, -0.6984,  ...,  0.5331,  1.5219,  0.0384]],\n",
       " \n",
       "         [[-0.6994, -0.1238, -0.2941,  ...,  0.0596, -0.1919, -0.6383],\n",
       "          [ 0.1102,  0.8171, -0.8330,  ...,  1.4833,  0.0372, -0.1265],\n",
       "          [-0.6337,  0.0302, -0.6471,  ..., -0.0646, -0.0414, -1.2111],\n",
       "          ...,\n",
       "          [ 0.7313,  0.1775, -0.9483,  ...,  1.1919,  0.1462,  1.1392],\n",
       "          [-0.3535, -0.0594, -0.1381,  ...,  0.4037, -0.4380, -0.0994],\n",
       "          [-0.6271, -1.2578, -0.3535,  ...,  0.8152,  1.3734, -0.6833]]],\n",
       "        device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " 'logits_for_regression': tensor([[[ 0.4625],\n",
       "          [ 1.1253],\n",
       "          [ 0.8932],\n",
       "          [-0.0898],\n",
       "          [-0.3464],\n",
       "          [ 0.3922],\n",
       "          [-0.6745],\n",
       "          [-0.2959],\n",
       "          [-0.3283],\n",
       "          [ 0.3412],\n",
       "          [-0.1999],\n",
       "          [-0.1936],\n",
       "          [-0.3279],\n",
       "          [ 0.3187],\n",
       "          [-0.2966],\n",
       "          [-0.0313],\n",
       "          [ 0.4524],\n",
       "          [ 0.5010],\n",
       "          [-0.6834],\n",
       "          [ 0.2558],\n",
       "          [ 0.4120],\n",
       "          [-0.5448],\n",
       "          [-0.8082],\n",
       "          [ 0.2053],\n",
       "          [-0.2170],\n",
       "          [ 0.6189],\n",
       "          [ 0.0466],\n",
       "          [-0.4912],\n",
       "          [ 0.1762],\n",
       "          [ 0.3051],\n",
       "          [ 0.0974],\n",
       "          [-0.4219]],\n",
       " \n",
       "         [[ 0.7257],\n",
       "          [ 1.1566],\n",
       "          [ 0.6295],\n",
       "          [-0.5771],\n",
       "          [-0.1743],\n",
       "          [ 0.3086],\n",
       "          [-0.9648],\n",
       "          [-0.0110],\n",
       "          [-0.2449],\n",
       "          [ 0.5497],\n",
       "          [-0.0265],\n",
       "          [-0.3618],\n",
       "          [-0.5325],\n",
       "          [ 0.2615],\n",
       "          [-0.4668],\n",
       "          [-0.3232],\n",
       "          [ 0.0197],\n",
       "          [ 0.5353],\n",
       "          [-0.4306],\n",
       "          [ 0.1355],\n",
       "          [ 0.2649],\n",
       "          [-0.5547],\n",
       "          [-0.9938],\n",
       "          [-0.1436],\n",
       "          [-0.2187],\n",
       "          [ 0.5986],\n",
       "          [ 0.1305],\n",
       "          [-0.3140],\n",
       "          [-0.1057],\n",
       "          [ 0.6423],\n",
       "          [ 0.1783],\n",
       "          [-0.3037]],\n",
       " \n",
       "         [[ 0.4225],\n",
       "          [ 1.1209],\n",
       "          [ 0.5867],\n",
       "          [-0.1844],\n",
       "          [-0.3613],\n",
       "          [ 0.1198],\n",
       "          [-0.7983],\n",
       "          [-0.6768],\n",
       "          [-0.2910],\n",
       "          [ 0.3985],\n",
       "          [-0.2072],\n",
       "          [ 0.2356],\n",
       "          [-0.3958],\n",
       "          [ 0.4437],\n",
       "          [-0.1831],\n",
       "          [-0.0213],\n",
       "          [ 0.3101],\n",
       "          [ 0.3396],\n",
       "          [-0.5407],\n",
       "          [ 0.0490],\n",
       "          [ 0.2819],\n",
       "          [-0.4986],\n",
       "          [-0.8936],\n",
       "          [ 0.0139],\n",
       "          [-0.1311],\n",
       "          [ 0.6600],\n",
       "          [ 0.1081],\n",
       "          [-0.3710],\n",
       "          [ 0.1274],\n",
       "          [ 0.5285],\n",
       "          [ 0.3038],\n",
       "          [-0.5198]],\n",
       " \n",
       "         [[ 0.6475],\n",
       "          [ 1.3006],\n",
       "          [ 0.7569],\n",
       "          [-0.3627],\n",
       "          [-0.1429],\n",
       "          [ 0.1332],\n",
       "          [-1.1839],\n",
       "          [-0.3978],\n",
       "          [-0.5411],\n",
       "          [ 0.3756],\n",
       "          [-0.2121],\n",
       "          [-0.4961],\n",
       "          [-0.6839],\n",
       "          [ 0.1033],\n",
       "          [-0.4021],\n",
       "          [-0.2861],\n",
       "          [-0.2430],\n",
       "          [ 0.4404],\n",
       "          [-0.4574],\n",
       "          [ 0.6430],\n",
       "          [-0.1227],\n",
       "          [-0.5008],\n",
       "          [-1.2832],\n",
       "          [-0.6627],\n",
       "          [-0.4713],\n",
       "          [ 0.4382],\n",
       "          [-0.4398],\n",
       "          [-0.1555],\n",
       "          [-0.4383],\n",
       "          [ 0.1841],\n",
       "          [-0.3641],\n",
       "          [-0.5515]]], device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " 'encoder_output': tensor([[[-1.0871, -0.9027, -1.0456,  ...,  2.1507,  0.2569,  0.3417],\n",
       "          [-0.0500, -0.0966,  0.6812,  ...,  0.0415, -0.2072,  0.8769],\n",
       "          [ 0.9258,  0.0990,  0.3053,  ...,  0.4459, -0.0286,  1.0480],\n",
       "          ...,\n",
       "          [-0.5066, -0.7059, -0.9433,  ...,  0.9339,  0.1780,  0.9655],\n",
       "          [ 0.7728,  0.2820,  0.0788,  ..., -1.2342, -0.3853, -0.0090],\n",
       "          [-0.6788, -0.4927,  0.2889,  ...,  1.3087,  1.3105, -0.4769]],\n",
       " \n",
       "         [[-1.1123, -0.9353, -1.0874,  ...,  1.5304,  0.1625,  0.6548],\n",
       "          [ 0.2740,  0.4918,  0.3134,  ...,  0.6726,  1.6726,  1.6206],\n",
       "          [ 0.9874,  0.2136,  0.3300,  ...,  0.7371, -0.0116,  1.3514],\n",
       "          ...,\n",
       "          [-1.0430, -0.5323, -0.4238,  ...,  0.7596,  0.1106,  1.0727],\n",
       "          [ 0.6165,  0.2448, -0.0190,  ..., -1.6127, -0.3009, -0.0152],\n",
       "          [-0.7605, -0.5280,  0.3837,  ...,  1.2890,  1.3002, -0.7094]],\n",
       " \n",
       "         [[-1.0529, -0.8296, -1.3953,  ...,  2.1331,  0.2836,  0.7182],\n",
       "          [-0.0588,  0.6916,  0.5615,  ...,  0.4994,  1.6001,  1.5735],\n",
       "          [ 0.8428, -0.0654,  0.1801,  ...,  0.6757, -0.3364,  1.3778],\n",
       "          ...,\n",
       "          [-0.6738, -0.5608, -0.5452,  ...,  1.1450,  0.0758,  1.2539],\n",
       "          [ 0.6292,  0.3244,  0.0508,  ..., -1.5323, -0.3021,  0.2706],\n",
       "          [-0.7968, -0.4107,  0.4764,  ...,  1.0717,  1.1997, -0.2350]],\n",
       " \n",
       "         [[-1.5140, -0.8813, -1.4527,  ...,  1.5817,  0.3290,  0.7486],\n",
       "          [-0.6634, -0.4517,  0.3725,  ..., -1.0084, -0.7813, -0.4509],\n",
       "          [ 1.0271,  0.1706,  0.0345,  ...,  0.6736, -0.2753,  1.4597],\n",
       "          ...,\n",
       "          [-0.2307, -0.6011, -0.7214,  ...,  0.9028,  0.5457,  1.8695],\n",
       "          [ 1.2760,  0.6890, -0.0087,  ..., -0.7534,  1.4241,  0.9715],\n",
       "          [ 0.7809,  0.2215, -0.7358,  ...,  1.5649,  0.8565, -1.8107]]],\n",
       "        device='cuda:0', grad_fn=<NativeLayerNormBackward0>)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[231, 136, 136,  ...,  26,  25,  10],\n",
       "         [231,  54, 149,  ..., 170, 151,  89],\n",
       "         [231,  54, 149,  ...,  10, 173,   5],\n",
       "         [231,  54, 186,  ..., 172,  79,  91]], device='cuda:0'),\n",
       " tensor([[inf, inf, inf,  ..., inf, inf, inf],\n",
       "         [inf, inf, inf,  ..., inf, inf, inf],\n",
       "         [inf, inf, inf,  ..., inf, inf, inf],\n",
       "         [inf, inf, inf,  ..., inf, inf, inf]], device='cuda:0'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.greedy_generate(batch['encoder_input'], \n",
    "                      encoder_input_labels=batch['encoder_input_labels'], \n",
    "                      max_length=500, \n",
    "                      encoder_padding_mask=batch['encoder_padding_mask'], \n",
    "                      continuous_token_ids=torch.tensor([tokenizer.vocab['[C]']]).to(model.device),\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "num_variables = 2\n",
    "field = 'QQ'\n",
    "max_coefficient = 100\n",
    "max_degree=20\n",
    "continous_ids = [2]\n",
    "\n",
    "params = {'encoding_method': 'standard',\n",
    "          'd_model': 256,\n",
    "          'nhead': 4,\n",
    "          'num_encoder_layers': 2,\n",
    "          'num_decoder_layers': 2,\n",
    "          'dim_feedforward': 1024,\n",
    "          'dropout': 0.1,\n",
    "          'max_sequence_length': 512,\n",
    "          'positional_encoding': 'embedding',\n",
    "          'regression_weight': 1.0,}\n",
    "\n",
    "import argparse\n",
    "\n",
    "params = argparse.Namespace(**params)\n",
    "\n",
    "vocab = set_vocab(num_variables, \n",
    "                  field=field, \n",
    "                  max_coeff=max_coefficient, \n",
    "                  max_degree=max_degree, \n",
    "                  continuous_coefficient=False, \n",
    "                continuous_exponent=False)\n",
    "tokenizer = set_tokenizer(vocab)\n",
    "model = load_model(params, vocab=vocab, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_pretrained_bag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bag \u001b[38;5;241m=\u001b[39m \u001b[43mload_pretrained_bag\u001b[49m(save_path)\n\u001b[1;32m      2\u001b[0m config, model, tokenizer \u001b[38;5;241m=\u001b[39m bag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m], bag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m], bag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_pretrained_bag' is not defined"
     ]
    }
   ],
   "source": [
    "bag = load_pretrained_bag(save_path)\n",
    "config, model, tokenizer = bag['config'], bag['model'], bag['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:10<00:00,  5.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from loader.data import _load_data\n",
    "from loader.data import SimpleDataCollator\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 500\n",
    "dataloader = data_path\n",
    "disable_tqdm = False\n",
    "max_length = 10000\n",
    "\n",
    "if isinstance(dataloader, str):\n",
    "    dataset = _load_data(dataloader)\n",
    "    dc = SimpleDataCollator(tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=dc, shuffle=False)\n",
    "\n",
    "# load model    \n",
    "if isinstance(model, str):\n",
    "    bag = load_pretrained_bag(model)\n",
    "    config, model, tokenizer = bag['config'], bag['model'], bag['tokenizer']\n",
    "else:\n",
    "    assert(tokenizer is not None)\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    hits = []\n",
    "    dataloader = tqdm(dataloader, disable=disable_tqdm)  if not disable_tqdm else dataloader\n",
    "    for batch in dataloader:\n",
    "        max_length = min(max_length, batch['labels'].shape[1] + 1)\n",
    "        outputs = model.greedy_generate(batch['encoder_input'].cuda(), max_length=max_length, encoder_padding_mask=batch['encoder_padding_mask'].cuda())\n",
    "        pred = tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)\n",
    "        target = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "        \n",
    "        hits += [p == t for p, t in zip(pred, target)]\n",
    "        \n",
    "    ret = {'acc': np.array(hits, dtype=float).mean(), 'hits': hits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.432"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ret['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, True, True, False, True, False, True, False]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret['hits'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder_input', 'decoder_input', 'encoder_padding_mask', 'decoder_padding_mask', 'labels'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "batch  = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 48.1 ms, total: 20.9 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = model.greedy_generate(batch['encoder_input'].cuda(), \n",
    "                                encoder_attention_mask=None,\n",
    "                                encoder_padding_mask=batch['encoder_padding_mask'].cuda(),\n",
    "                                max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36,  4, 12, 11, 32,  4, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  4, 11, 13, 40,  4, 11, 14, 32,  5, 11, 13, 32,  5,\n",
       "         11, 12, 32,  5, 11, 11, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 15, 38, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  8, 11, 14, 32,  9, 11, 12, 32,  9, 11, 11, 40,  4,\n",
       "         11, 15, 32,  9, 11, 14, 32,  8, 11, 13, 32,  8, 11, 12, 38, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 12, 11, 32,  4, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  4, 11, 13, 40,  4, 11, 14, 32,  8, 11, 11, 38, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 15, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  8, 11, 14, 32,  9, 11, 12, 32,  9, 11, 11, 40,  4, 11,\n",
       "         15, 32,  9, 11, 14, 32,  8, 11, 13, 32,  8, 11, 12, 38, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E0 E3 + C2 E0 E2 + C2 E0 E1 + C2 E0 E0'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E0 E3 + C5 E0 E0'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E3 E1 + C1 E2 E3 + C5 E2 E2 + C5 E1 E4 + C1 E1 E2 + C5 E1 E1 + C3 E1 E0 + C6 E0 E3 + C3 E0 E2 + C2 E0 E1 + C5 E0 E0 [SEP] C4 E5 E2 + C4 E4 E4 + C4 E4 E1 + C4 E3 E3 + C6 E3 E2 + C5 E3 E1 + C3 E2 E5 + C3 E2 E4 + C5 E2 E3 + C3 E2 E1 + C1 E2 E0 + C2 E1 E4 + C1 E1 E3 + C1 E1 E2 + C2 E0 E4 + C5 E0 E3 + C1 E0 E2 + C3 E0 E1 + C2 E0 E0'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['encoder_input'], skip_special_tokens=True)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E9': 20,\n",
       " 'C0': 3,\n",
       " 'E12': 23,\n",
       " '[UNK]': 41,\n",
       " '/': 35,\n",
       " 'E10': 21,\n",
       " 'E2': 13,\n",
       " 'C2': 5,\n",
       " 'E17': 28,\n",
       " '[SEP]': 40,\n",
       " '^': 34,\n",
       " 'E14': 25,\n",
       " 'E18': 29,\n",
       " '</s>': 38,\n",
       " '<s>': 37,\n",
       " 'E3': 14,\n",
       " '+': 32,\n",
       " 'C3': 6,\n",
       " 'E8': 19,\n",
       " 'E13': 24,\n",
       " 'E0': 11,\n",
       " 'E5': 16,\n",
       " '[PAD]': 36,\n",
       " 'E4': 15,\n",
       " 'C4': 7,\n",
       " 'E20': 31,\n",
       " 'C1': 4,\n",
       " 'C5': 8,\n",
       " '[C]': 2,\n",
       " 'C6': 9,\n",
       " '[E]': 10,\n",
       " 'E19': 30,\n",
       " '[CLS]': 39,\n",
       " '*': 33,\n",
       " 'E16': 27,\n",
       " 'E1': 12,\n",
       " 'E11': 22,\n",
       " 'x0': 0,\n",
       " 'x1': 1,\n",
       " 'E15': 26,\n",
       " 'E7': 18,\n",
       " 'E6': 17}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.3",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "sage",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
