{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/app/src')\n",
    "import torch\n",
    "import os\n",
    "import sys \n",
    "import wandb\n",
    "import numpy as np\n",
    "from loader.data import _load_data, DataCollatorForNumAdditions, GenerateLabels\n",
    "from dataset.tokernizer import set_tokenizer, set_vocab_for_num_additions\n",
    "from torch.utils.data import DataLoader\n",
    "from loader.model import load_model_for_num_additions\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from trainer.trainer import CustomTrainer as Trainer\n",
    "from trainer.trainer import CustomTrainingArguments as TrainingArguments\n",
    "\n",
    "# これをしないと，sagemathが勝手にintやfloatをinteger型やRealNuber型に変換してしまうしてしまう\n",
    "preparser(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_variables = 3\n",
    "field = 'GF7'\n",
    "max_coefficient = 200\n",
    "max_degree=20\n",
    "continous_ids = [2]\n",
    "\n",
    "params = {'encoding_method': 'standard',\n",
    "          'd_model': 512,\n",
    "          'nhead': 8,\n",
    "          'num_encoder_layers': 6,\n",
    "          'num_decoder_layers': 6,\n",
    "          'dim_feedforward': 2048,\n",
    "          'dropout': 0.1,\n",
    "          'max_sequence_length': 10000,\n",
    "          'positional_encoding': 'embedding',\n",
    "          'regression_weight': 1.0,}\n",
    "\n",
    "import argparse\n",
    "\n",
    "params = argparse.Namespace(**params)\n",
    "\n",
    "trainset = _load_data(f'./data/pred_nadds/pred_nadds_n={num_variables}_field=GF7/F_matrix_nadds/train.F_matrix_nadds')\n",
    "testset = _load_data(f'./data/pred_nadds/pred_nadds_n={num_variables}_field=GF7/F_matrix_nadds/test.F_matrix_nadds')\n",
    "\n",
    "\n",
    "vocab = set_vocab_for_num_additions(num_variables, \n",
    "                  field=field, \n",
    "                  max_coeff=max_coefficient, \n",
    "                  max_degree=max_degree,\n",
    "                  weight_mx_entry_bound=1000, \n",
    "                  continuous_coefficient=False, \n",
    "                continuous_exponent=False)\n",
    "\n",
    "tokenizer = set_tokenizer(vocab)\n",
    "# bins = np.array([0, 100, 150, 200, 400, 1000, 2000, 3000, 4000, 5000])\n",
    "bins = np.array([0, 500])\n",
    "\n",
    "num_classes = len(bins)\n",
    "generate_labels = GenerateLabels(bins, True)\n",
    "dc = DataCollatorForNumAdditions(tokenizer, generate_labels)\n",
    "label_names = ['labels']\n",
    "model = load_model_for_num_additions(params, num_classes=num_classes, vocab=vocab, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up trainer\n",
    "trainer_config = TrainingArguments(\n",
    "    output_dir                  = './output_tameshi',\n",
    "    num_train_epochs            = 8,\n",
    "    # max_steps_per_epoch         = params.max_steps_per_epoch,\n",
    "    logging_steps               = 50,\n",
    "    save_total_limit            = 1,\n",
    "    dataloader_pin_memory       = True,\n",
    "    bf16                        = True,\n",
    "    # save_steps                  = 100,\n",
    "    eval_steps                  = 100,\n",
    "    label_names                 = label_names, \n",
    "    remove_unused_columns       = False,\n",
    "    # per_device_train_batch_size = params.batch_size // count_cuda_devices(),\n",
    "    eval_strategy               = 'steps',\n",
    "    # torch_compile               = True,\n",
    "    report_to                   = 'none',\n",
    "    disable_tqdm                = True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        args                            = trainer_config,\n",
    "        model                           = model,\n",
    "        train_dataset                   = trainset,\n",
    "        eval_dataset                    = testset,\n",
    "        data_collator                   = dc,\n",
    "        # compute_metrics                 = _compute_metrics,\n",
    "        # preprocess_logits_for_metrics   = preprocess_logits_for_metrics,\n",
    "        # callbacks                       = [limit_steps_callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input torch.Size([16, 791])\n",
      "encoder_padding_mask torch.Size([16, 791])\n",
      "labels torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(trainset, collate_fn=dc, batch_size=16, shuffle=False)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.2689],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']\n",
    "# batch['encoder_padding_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2039"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab['[PAD]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '[UNK]', '[SEP]', '[PAD]', '[CLS]']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.2689],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.2689, 0.7311],\n",
       "        [0.7311, 0.2689],\n",
       "        [0.7311, 0.2689]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n",
      "float64\n",
      "[[0.19661193 0.53444665 0.19661193 0.07232949]\n",
      " [0.07232949 0.19661193 0.53444665 0.19661193]\n",
      " [0.0320586  0.08714432 0.23688282 0.64391426]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([1, 2, 3], dtype=np.int64)\n",
    "num_classes = 4\n",
    "\n",
    "# one_hot_labels = np.eye(num_classes)[labels]\n",
    "# print(one_hot_labels)\n",
    "\n",
    "# # soft_A = np.exp(A) / np.sum(np.exp(A))\n",
    "# # soft_A\n",
    "# correct_class = 3\n",
    "# B = np.arange(num_classes)\n",
    "# print(B)\n",
    "# C = np.ones(num_classes) * correct_class\n",
    "# print(C)\n",
    "# D = C - B\n",
    "# print(D)\n",
    "# D = -np.abs(D)\n",
    "# E = np.exp((D)) / np.sum(np.exp(D))\n",
    "# print(E)\n",
    "\n",
    "def get_soft_label(correct_class_id, num_classes):\n",
    "    assert 0 <= correct_class_id and correct_class_id < num_classes, 'correct_class_id は0以上かつnum_classes未満の整数である必要がある'\n",
    "    \n",
    "    diffs = np.ones(num_classes) * correct_class_id - np.arange(num_classes)\n",
    "    dist = np.abs(diffs)\n",
    "    get_soft_label = np.exp(-dist) / np.sum(np.exp(-dist))\n",
    "    print(get_soft_label.dtype)\n",
    "    return get_soft_label\n",
    "\n",
    "\n",
    "\n",
    "soft_labels = np.zeros((0, num_classes))\n",
    "for label in labels:\n",
    "    soft_labels = np.vstack((soft_labels, get_soft_label(label, num_classes)))\n",
    "\n",
    "print(soft_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2787/3188335668.py:1: DeprecationWarning: This function is deprecated. Please call randint(0, 3 + 1) instead\n",
      "  np.random.random_integers(0, 3, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3, 0, 2, 2, 3, 0, 0, 2, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random_integers(0, 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.3",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
