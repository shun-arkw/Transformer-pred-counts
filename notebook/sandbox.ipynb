{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd '/app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "sys.path.append('/app/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader.checkpoint import load_pretrained_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'shape'\n",
    "encoding = 'standard'\n",
    "\n",
    "n, field = 2, 'GF7'\n",
    "data_name = f'{task}_n={n}_field={field}'\n",
    "data_path = f'data/{task}/{data_name}/data_{field}_n={n}.test.lex.infix'\n",
    "\n",
    "data_config_path = f'config/{data_name}.yaml'\n",
    "_save_path = f'{field}_n={n}_ep=8_bs=16'\n",
    "save_path = f'results/{task}/{encoding}_embedding/{_save_path}'\n",
    "# save_path = f'results/{task}/{encoding}/dryrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = load_pretrained_bag(save_path)\n",
    "config, model, tokenizer = bag['config'], bag['model'], bag['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:02<00:02,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from loader.data import _load_data\n",
    "from loader.data import SimpleDataCollator\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 500\n",
    "dataloader = data_path\n",
    "disable_tqdm = False\n",
    "max_length = 10000\n",
    "\n",
    "if isinstance(dataloader, str):\n",
    "    dataset = _load_data(dataloader)\n",
    "    dc = SimpleDataCollator(tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=dc, shuffle=False)\n",
    "\n",
    "# load model    \n",
    "if isinstance(model, str):\n",
    "    bag = load_pretrained_bag(model)\n",
    "    config, model, tokenizer = bag['config'], bag['model'], bag['tokenizer']\n",
    "else:\n",
    "    assert(tokenizer is not None)\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    hits = []\n",
    "    dataloader = tqdm(dataloader, disable=disable_tqdm)  if not disable_tqdm else dataloader\n",
    "    for batch in dataloader:\n",
    "        max_length = min(max_length, batch['labels'].shape[1] + 1)\n",
    "        outputs = model.greedy_generate(batch['encoder_input'].cuda(), max_length=max_length, encoder_padding_mask=batch['encoder_padding_mask'].cuda())\n",
    "        pred = tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)\n",
    "        target = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "        \n",
    "        hits += [p == t for p, t in zip(pred, target)]\n",
    "        \n",
    "    ret = {'acc': np.array(hits, dtype=float).mean(), 'hits': hits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.432"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ret['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, True, True, False, True, False, True, False]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret['hits'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder_input', 'decoder_input', 'encoder_padding_mask', 'decoder_padding_mask', 'labels'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch  = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 48.1 ms, total: 20.9 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = model.greedy_generate(batch['encoder_input'].cuda(), \n",
    "                                encoder_attention_mask=None,\n",
    "                                encoder_padding_mask=batch['encoder_padding_mask'].cuda(),\n",
    "                                max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36,  4, 12, 11, 32,  4, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  4, 11, 13, 40,  4, 11, 14, 32,  5, 11, 13, 32,  5,\n",
       "         11, 12, 32,  5, 11, 11, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 15, 38, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  8, 11, 14, 32,  9, 11, 12, 32,  9, 11, 11, 40,  4,\n",
       "         11, 15, 32,  9, 11, 14, 32,  8, 11, 13, 32,  8, 11, 12, 38, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 12, 11, 32,  4, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  4, 11, 13, 40,  4, 11, 14, 32,  8, 11, 11, 38, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 15, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  8, 11, 14, 32,  9, 11, 12, 32,  9, 11, 11, 40,  4, 11,\n",
       "         15, 32,  9, 11, 14, 32,  8, 11, 13, 32,  8, 11, 12, 38, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E0 E3 + C2 E0 E2 + C2 E0 E1 + C2 E0 E0'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E0 E3 + C5 E0 E0'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E3 E1 + C1 E2 E3 + C5 E2 E2 + C5 E1 E4 + C1 E1 E2 + C5 E1 E1 + C3 E1 E0 + C6 E0 E3 + C3 E0 E2 + C2 E0 E1 + C5 E0 E0 [SEP] C4 E5 E2 + C4 E4 E4 + C4 E4 E1 + C4 E3 E3 + C6 E3 E2 + C5 E3 E1 + C3 E2 E5 + C3 E2 E4 + C5 E2 E3 + C3 E2 E1 + C1 E2 E0 + C2 E1 E4 + C1 E1 E3 + C1 E1 E2 + C2 E0 E4 + C5 E0 E3 + C1 E0 E2 + C3 E0 E1 + C2 E0 E0'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['encoder_input'], skip_special_tokens=True)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E9': 20,\n",
       " 'C0': 3,\n",
       " 'E12': 23,\n",
       " '[UNK]': 41,\n",
       " '/': 35,\n",
       " 'E10': 21,\n",
       " 'E2': 13,\n",
       " 'C2': 5,\n",
       " 'E17': 28,\n",
       " '[SEP]': 40,\n",
       " '^': 34,\n",
       " 'E14': 25,\n",
       " 'E18': 29,\n",
       " '</s>': 38,\n",
       " '<s>': 37,\n",
       " 'E3': 14,\n",
       " '+': 32,\n",
       " 'C3': 6,\n",
       " 'E8': 19,\n",
       " 'E13': 24,\n",
       " 'E0': 11,\n",
       " 'E5': 16,\n",
       " '[PAD]': 36,\n",
       " 'E4': 15,\n",
       " 'C4': 7,\n",
       " 'E20': 31,\n",
       " 'C1': 4,\n",
       " 'C5': 8,\n",
       " '[C]': 2,\n",
       " 'C6': 9,\n",
       " '[E]': 10,\n",
       " 'E19': 30,\n",
       " '[CLS]': 39,\n",
       " '*': 33,\n",
       " 'E16': 27,\n",
       " 'E1': 12,\n",
       " 'E11': 22,\n",
       " 'x0': 0,\n",
       " 'x1': 1,\n",
       " 'E15': 26,\n",
       " 'E7': 18,\n",
       " 'E6': 17}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
